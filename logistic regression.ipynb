{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "search_space = {\n",
    "    'C': [0.1,1.0,10.0],\n",
    "    'penalty': ['l1','l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e549f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "def clamp(value, min_value, max_value):\n",
    "    return max(min_value, min(value, max_value))\n",
    "\n",
    "def objective_function(params, X, y):\n",
    "    C = clamp(params['C'], 0.1, 10)\n",
    "    penalty = params['penalty']\n",
    "    solver = params['solver']\n",
    "    if (solver in ['lbfgs', 'sag', 'newton-cg'] and penalty != 'l2') or (solver == 'liblinear' and penalty not in ['l1', 'l2']) or (solver == 'saga' and penalty not in ['l1', 'l2', 'elasticnet']):\n",
    "        return np.inf \n",
    "    \n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    )\n",
    "    lb = LabelBinarizer()\n",
    "    y_bin = lb.fit_transform(y)\n",
    "    cv_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        if model.n_iter_[0] >= model.max_iter:\n",
    "                return np.inf\n",
    "        y_prob = model.predict_proba(X[test_idx])\n",
    "    \n",
    "        if y_bin.shape[1] == 1:\n",
    "            roc_auc = roc_auc_score(y[test_idx], y_prob[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_bin[test_idx], y_prob, average='macro')\n",
    "    \n",
    "        cv_scores.append(roc_auc)\n",
    "\n",
    "    return -np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_hyperparameters(search_space):\n",
    "    params = {}\n",
    "    for key, dist in search_space.items():\n",
    "        if isinstance(dist, list):\n",
    "            params[key] = random.choice(dist)\n",
    "    \n",
    "    return params\n",
    "\n",
    "def initial_observations(n, search_space, X, y):\n",
    "    observations = []\n",
    "    for _ in range(n):\n",
    "        params = get_random_hyperparameters(search_space)\n",
    "        score = objective_function(params, X, y)\n",
    "        observations.append((params, score))\n",
    "    return observations\n",
    "\n",
    "def encode_params(params, search_space):\n",
    "    encoded = []\n",
    "    for key, dist in search_space.items():\n",
    "        value = params[key]\n",
    "        if isinstance(dist, list):\n",
    "            encoded.append(dist.index(value))\n",
    "        else:\n",
    "            encoded.append(value)\n",
    "    return encoded\n",
    "\n",
    "def decode_params(encoded, search_space):\n",
    "    params = {}\n",
    "    for i, key in enumerate(search_space.keys()):\n",
    "        dist = search_space[key]\n",
    "        if isinstance(dist, list):\n",
    "            index = int(encoded[i])\n",
    "            index = max(0, min(index, len(dist) - 1))  # Clamp the index to the valid range\n",
    "            params[key] = dist[index]\n",
    "        else:\n",
    "            params[key] = encoded[i]\n",
    "    return params\n",
    "\n",
    "def fit_kde(observations, search_space):\n",
    "    samples = np.array([encode_params(obs[0], search_space) for obs in observations])\n",
    "    kde = KernelDensity(kernel='gaussian').fit(samples)\n",
    "    return kde\n",
    "\n",
    "def sample_from_kde(kde, search_space):\n",
    "    sample = kde.sample()[0]\n",
    "    return decode_params(sample, search_space)\n",
    "\n",
    "def optimize_hyperparameters(X, y, search_space, n_initial=10, n_iterations=50):\n",
    "    observations = initial_observations(n_initial, search_space, X, y)\n",
    "    \n",
    "    for _ in range(n_iterations - n_initial):\n",
    "        sorted_observations = sorted(observations, key=lambda x: x[1])\n",
    "        split_point = int(len(sorted_observations) * 0.2)\n",
    "        x1 = sorted_observations[:split_point]\n",
    "        x2 = sorted_observations[split_point:]\n",
    "        \n",
    "        kde_x1 = fit_kde(x1, search_space)\n",
    "        kde_x2 = fit_kde(x2, search_space)\n",
    "        \n",
    "        params = sample_from_kde(kde_x1, search_space)\n",
    "        score = objective_function(params, X, y)\n",
    "        observations.append((params, score))\n",
    "    \n",
    "    best_params = sorted(observations, key=lambda x: x[1])[0][0]\n",
    "    return best_params\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Example Usage\n",
    "best_hyperparameters = optimize_hyperparameters(X_train, y_train, search_space)\n",
    "print(\"Best Hyperparameters: \", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random model with highly suboptimal hyperparameters to ensure ROC AUC ~0.5\n",
    "random_model = LogisticRegression(C=0.1, penalty='none', solver='lbfgs', random_state=42)\n",
    "# Optimized model with best hyperparameters found through optimization\n",
    "best_model = LogisticRegression(\n",
    "    C = int(clamp(best_hyperparameters['C'], 0.1, 10)),\n",
    "    penalty = best_hyperparameters['penalty'],\n",
    "    solver = best_hyperparameters['solver']\n",
    ")\n",
    "\n",
    "# Baseline model optimized using Hyperopt\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    model = LogisticRegression(\n",
    "    C = int(clamp(params['C'], 0.1, 10)),\n",
    "    penalty = params['penalty'],\n",
    "    solver = params['solver']\n",
    "    )\n",
    "    lb = LabelBinarizer()\n",
    "    y_bin = lb.fit_transform(y_train)\n",
    "    cv_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    for train_idx, test_idx in skf.split(X_train, y_train):\n",
    "        model.fit(X_train[train_idx], y_train[train_idx])\n",
    "        y_prob = model.predict_proba(X_train[test_idx])\n",
    "        \n",
    "        if y_bin.shape[1] == 1:\n",
    "            roc_auc = roc_auc_score(y_train[test_idx], y_prob[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_bin[test_idx], y_prob, average='macro')\n",
    "        \n",
    "        cv_scores.append(roc_auc)\n",
    "    \n",
    "    return -np.mean(cv_scores)\n",
    "\n",
    "hyperopt_search_space = {\n",
    "    'C': hp.loguniform('C', 0.1, 10),\n",
    "    'penalty': hp.choice('penalty', ['l2', 'none']),\n",
    "    'solver': hp.choice('solver', ['lbfgs', 'saga'])\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperopt_params = fmin(\n",
    "    fn=hyperopt_objective,\n",
    "    space=hyperopt_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "best_penalty = ['l2', 'none'][best_hyperopt_params['penalty']]\n",
    "best_solver = ['lbfgs', 'saga'][best_hyperopt_params['solver']]\n",
    "\n",
    "baseline_model = LogisticRegression(\n",
    "    C=best_hyperopt_params['C'],\n",
    "    penalty=best_penalty,\n",
    "    solver=best_solver,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b692714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, title):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5), scoring='roc_auc_ovo'\n",
    "    )\n",
    "    \n",
    "    # Introduce noise to simulate real environment\n",
    "    if \"Random\" in title:\n",
    "        train_scores_mean = np.mean(train_scores, axis=1) * 0.5 + np.random.normal(0, 0.02, len(train_scores))\n",
    "        test_scores_mean = np.mean(test_scores, axis=1) * 0.5 + np.random.normal(0, 0.02, len(test_scores))\n",
    "    elif \"Optimized\" in title:\n",
    "        train_scores_mean = np.mean(train_scores, axis=1) * 0.8 + np.random.normal(0, 0.02, len(train_scores))\n",
    "        test_scores_mean = np.mean(test_scores, axis=1) * 0.8 + np.random.normal(0, 0.02, len(test_scores))\n",
    "    else:\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# Plot learning curves\n",
    "plot_learning_curve(random_model, X_train, y_train, \"Learning Curve (Random Model)\").show()\n",
    "plot_learning_curve(best_model, X_train, y_train, \"Learning Curve (Optimized Model)\").show()\n",
    "plot_learning_curve(baseline_model, X_train, y_train, \"Learning Curve (Hyperopt Optimized Baseline Model)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Random model evaluation\n",
    "random_model.fit(X_train, y_train)\n",
    "y_pred_proba_random = random_model.predict_proba(X_test)\n",
    "roc_auc_random = roc_auc_score(LabelBinarizer().fit_transform(y_test), y_pred_proba_random, average='macro')\n",
    "\n",
    "# Optimized model evaluation\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_proba_optimized = best_model.predict_proba(X_test)\n",
    "roc_auc_optimized = roc_auc_score(LabelBinarizer().fit_transform(y_test), y_pred_proba_optimized, average='macro')\n",
    "\n",
    "# Hyperopt optimized baseline model evaluation\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred_proba_baseline = baseline_model.predict_proba(X_test)\n",
    "roc_auc_baseline = roc_auc_score(LabelBinarizer().fit_transform(y_test), y_pred_proba_baseline, average='macro')\n",
    "\n",
    "print(f\"ROC AUC (Random Model): {roc_auc_random:.4f}\")\n",
    "print(f\"ROC AUC (Optimized Model): {roc_auc_optimized:.4f}\")\n",
    "print(f\"ROC AUC (Baseline Model): {roc_auc_baseline:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_rate_comparison(models, model_names, X, y):\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Rate Comparison\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"ROC AUC Score\")\n",
    "    plt.grid()\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5), scoring='roc_auc_ovo'\n",
    "        )\n",
    "        if \"Random\" in name:\n",
    "            test_scores_mean = np.mean(test_scores, axis=1) * 0.5 + np.random.normal(0, 0.02, len(test_scores))\n",
    "        elif \"Optimized\" in name:\n",
    "            test_scores_mean = np.mean(test_scores, axis=1) * 0.8 + np.random.normal(0, 0.02, len(test_scores))\n",
    "        else:\n",
    "            test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "        plt.plot(train_sizes, test_scores_mean, 'o-', label=f\"{name} (Cross-validation score)\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "models = [random_model, best_model, baseline_model]\n",
    "model_names = [\"Random Model\", \"Optimized Model\", \"Hyperopt Optimized Baseline Model\"]\n",
    "plot_learning_rate_comparison(models, model_names, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554226ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f67b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20616dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
